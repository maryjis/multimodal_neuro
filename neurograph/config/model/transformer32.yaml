defaults:
    - base_transformer

hidden_dim: 32 
head_config:
    act_func: null
    act_func_params: null
    layers:
        - {out_size: 16, dropout: 0.5, act_func: 'GELU', act_func_params: null}
