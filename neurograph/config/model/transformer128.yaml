defaults:
    - base_transformer

hidden_dim:  128
head_config:
    act_func: null
    act_func_params: null
    layers:
        - {out_size: 64, dropout: 0.5, act_func: 'GELU', act_func_params: null}
