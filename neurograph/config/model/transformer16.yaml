defaults:
    - base_transformer

hidden_dim: 16 
head_config:
    act_func: null
    act_func_params: null
    layers:
        - {out_size: 8, dropout: 0.5, act_func: 'GELU', act_func_params: null}
